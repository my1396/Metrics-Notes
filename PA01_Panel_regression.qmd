---
title: "Panel Regressions"
format: html
---

```{r}
#| child: "_chunk-opt.qmd"
#| include: false
```


Example: Data from Grunfeld (1958).

- 20 annual observations (1935–1954).
- 11 large US firms.
- Three variables: real gross investment (`invest`), real value of the firm (`value`), and real value of the capital stock (`capital`).

Data structure:

- Two-dimensional index.
- Cross-sectional objects are called "individuals".
- Time identifier is called "time".

Data handling: Select subset of three firms for illustration and declare
individuals ("firm") and time identifier ("year").

```{r}
data("Grunfeld", package = "AER")
library(plm)
gr <- subset(Grunfeld, firm %in% c("General Electric", "General Motors", "IBM"))
pgr <- pdata.frame(gr, index = c("firm", "year"), drop.index = FALSE)
```


## Pooled model

Pooled model:

$$
invest_{it} = \beta_0 + \beta_1\, value_{it} + \beta_2\, capital_{it} + e_{it}.
$$


```{r}
gr_pool <- plm(invest ~ value + capital, data = pgr, model = "pooling")
summary(gr_pool)
```

## Fixed Effects

Individual fixed effects
$$
\begin{aligned}
invest_{it} 
&= \beta_1\, value_{it} + \beta_2\, capital_{it} + \alpha_i + e_{it} \\
&= \bx'_{it}\bbeta  + \alpha_i + e_{it} .
\end{aligned}
$$

Assumptions

$$
\begin{aligned}
\E[e_{it}] &= 0 \\
\E[\bx_{it}e_{it}] &= 0 \\
\E[\alpha_{it}e_{it}] &= 0 \\
\end{aligned}
$$

```{r}
gr_fe <- plm(invest ~ value + capital, data = pgr, effect = "individual", model = "within")
summary(gr_fe)
```


Q: Are the fixed effects really needed? 

A: Compare fixed effects and pooled OLS fits via `pFtest()`.

```{r}
pFtest(gr_fe, gr_pool)
```

This indicates substantial inter-firm variation.


Two-way fixed effects
$$
invest_{it} = \beta_1\, value_{it} + \beta_2\, capital_{it} + \alpha_i + \gamma_t + e_{it}.
$$

```{r}
gr_fe2 <- plm(invest ~ value + capital, data = pgr, effect = "twoways", model = "within")
summary(gr_fe2)
```


## Random Effects

Model specification same as fixed effects but with **different assumptions**.

$$
\begin{aligned}
invest_{it} 
&= \beta_1\, value_{it} + \beta_2\, capital_{it} + \alpha_i + e_{it} \\
&= \bx'_{it}\bbeta  + \alpha_i + e_{it} .
\end{aligned}
$$

Assumptions

$$
\begin{aligned}
\E[e_{it}] &= 0 \\
\E[\bx_{it}e_{it}] &= 0 \\
\E[\alpha_{it}e_{it}] &= 0 \\
\E[\bx_{it}\alpha_{i}] &= 0 \Leftarrow \text{New assumption}\\
\end{aligned}
$$

$\E[\bx_{it}u_{it}] = 0$ imposes uncorrelation between the covariates ($\bx_{it}$) and the fixed effects ($u_{i}$). 

By contrast, in the fixed effects model, there is no such constraint, we can think of $u_i$ as random, but potentially correlated with $\bx_{it}.$

> In the panel data literature, approaches that do not restrict the dependence between the unobserved and the observed components are called “fixed effects.”


Random effects models is estimated by generalized least squares (GLS) by specify `model = "random"` in `plm()` call.

```{r}
# Using Wallace-Hussain for Grunfeld data.
gr_re <- plm(invest ~ value + capital, data = pgr, model = "random", random.method = "walhus")
summary(gr_re)
```

Recall: Random-effects estimator is essentially FGLS estimator, utilizing OLS after "quasi-demeaning" all variables.
Precise form of quasi-demeaning depends on `random.method` selected.
Four methods available: Swamy-Arora (default), Amemiya, Wallace-Hussain, and Nerlove.

Comparison of regression coefficients shows that fixed- and random-effects methods yield rather similar results for these data.

Q: Are the random effects really needed? 

A: Use Lagrange multiplier test. Several versions available in `plmtest()`.

```{r}
plmtest(gr_pool)
```

Test also suggests that some form of parameter heterogeneity must be taken into account.

Random-effects methods more efficient than fixed-effects estimator under more restrictive assumptions, namely **exogeneity of the individual effects**.

Use Hausman test to test for endogeneity.

$$
H_0: \text{The individual effects are uncorrelated with other regressors.}
$$

```{r}
phtest(gr_re, gr_fe)
```

In line with estimates presented above, endogeneity does not appear to
be a problem here. We can apply the Random effects model here.


## Dynamic Linear Models

@Arellano1991 employ an unbalanced panel of $n=140$ firms located in the UK. The dataset spans $T=9$ time periods and is available from R package `plm`. @Arellano1991 investigate employment equations and consider the dynamic specification:

$$
\begin{split}
emp_{i,t} 
&= \alpha_1 emp_{i,t-1} + \alpha_2 emp_{i,t-2} + \bbeta'(L) \bx_{it} + \lambda_t + \eta_i + \varepsilon_{i,t} \\
&= \alpha_1 emp_{i,t-1} + \alpha_2 emp_{i,t-2}  \\
&\phantom{=}\quad  + \beta_1 wage_{i,t} + \beta_2 wage_{i,t-1} \\
&\phantom{=}\quad  + \beta_3 capital_{i,t} + \beta_4 capital_{i,t-1} + \beta_5 capital_{i,t-2} \\
&\phantom{=}\quad + \beta_6 output_{i,t} + \beta_7 output_{i,t-1} + \beta_8 output_{i,t-2}  \\
&\phantom{=}\quad + \gamma_3 d_3 + \dots + \gamma_T d_T + \eta_i + \varepsilon_{i,t},
\end{split}
$$ {#eq-ABEstimation}

where $i = 1,...,n$ denotes the firm, and $t = 3,...,T$ is the time series dimension. The vector $\bx_{it}$ contains a set of explanatory variables and $\bbeta(L)$ is a vector of polynomials in the lag operator.

The natural logarithm of employment ($emp$) is explained by its first two lags and the further covariates 

- natural logarithm of wage ($wage$) and its first order of lag, 

- the natural logarithm of capital ($capital$) and its first and second lags, 

- the natural logarithm of output ($output$), and its first and second lags. 

- Variables $d_3, \ldots, d_T$  are time dummies with corresponding coefficients $\gamma_3, \ldots, \gamma_T$; 

- unobserved individual-specific effects are represented by $\eta_i$, and

- $\varepsilon_{i,t}$ is an error term.

The goal of the empirical analysis is to estimate the lag parameters $\alpha_1$ and  $\alpha_2$ and the coefficients $\beta_j$ of the $j=1,\ldots,8$ further covariates while controlling for (unobserved) time effects and accounting for unobserved individual-specific heterogeneity. 


--------------------------------------------------------------------------------

Let's first run a simplified regression with `pgmm`.

```{r}
data("EmplUK", package = "plm")
form <- log(emp) ~ log(wage) + log(capital) + log(output)
```

Arellano-Bond estimator is provided by `pgmm()`. Dynamic formula derived from static formula via list of lags.

GitHub repo for `pgmm`: <https://github.com/cran/plm/blob/59318399c6eb7bcaeb1d0560f1ce08882f0f55c1/R/est_gmm.R#L159>


```{r}
# Arellano and Bond (1991), table 4, col. b 
empl_ab <- pgmm(
    dynformula(form, list(2, 1, 0, 1)),
    data = EmplUK, index = c("firm", "year"),
    effect = "twoways", model = "twosteps",
    transform = "d",
    gmm.inst = ~ log(emp), lag.gmm = list(c(2, 3)) 
    )
```

Dynamic model with

- $p=2$ lagged endogenous terms
- $\log(wage)$  and $\log(output)$ occur up to lag 1
- $\log(capital)$ contemporaneous term only
- time- and firm-specific effects,
- instruments are lagged terms of the dependent variable (all lags
beyond lag 1 are to be used).
- `transform = "d"` uses the "difference GMM" model (see Arellano and Bond 1991) or "ld" for the "system GMM" model (see Blundell and Bond 1998).

```{r}
summary(empl_ab)
```


**Interpretation**: Autoregressive dynamics important for these data.

**Diagnostics**: 

- Sargan test: Assesses the validity of the instruments. A p-value of 0.2 indicates the instruments are valid.

- Autocorrelation test (1): Tests for first-order serial correlation. A p-value > 0.05 indicates that first-order serial correlation is not present.

    The autocorrelation test is based on Arellano and Bond Serial Correlation Test. The null hypothesis is that there is no serial correlation of a particular order. The test statistic is computed as proposed by @Arellano1991 and @Arellano2003.
    
    - p-value < 0.05 indicates the presence of serial correlation.

- Wald Tests: Assesses the joint significance of all the coefficients or time dummies in the model. The p-value < 0.05 confirms the coefficients and time dummies significantly affect the dependent variable.

**Note**: Due to constructing lags and taking first differences, three cross
sections are lost. Hence, estimation period is 1979–1984 and only 611
observations effectively available for estimation.


`pgmm.W`: a list of instruments matrices for every individual

```{r}
# print the instrument matrix for firm 1
empl_ab$W[[1]]
```

--------------------------------------------------------------------------------

Dynamic models using `pdynmc`.

```{r}
# compute logarithms of variables
EmplUK_log <- EmplUK
EmplUK_log[,c(4:7)] <- log(EmplUK_log[,c(4:7)])
head(EmplUK_log)

## data structure check for unbalancedness
library(pdynmc)
data.info(EmplUK_log, i.name = "firm", t.name = "year")
strucUPD.plot(EmplUK_log, i.name = "firm", t.name = "year")

# Run pdynmc
m1 <- pdynmc(
    dat = EmplUK_log, varname.i = "firm", varname.t = "year",
    use.mc.diff = TRUE, use.mc.lev = FALSE, use.mc.nonlin = FALSE,
    include.y = TRUE, varname.y = "emp", lagTerms.y = 2,
    fur.con = TRUE, fur.con.diff = TRUE, fur.con.lev = FALSE,
    varname.reg.fur = c("wage", "capital", "output"), lagTerms.reg.fur = c(1,2,2),
    include.dum = TRUE, dum.diff = TRUE, dum.lev = FALSE, varname.dum = "year",
    w.mat = "iid.err", std.err = "corrected",
    estimation = "onestep", opt.meth = "none" 
    )


summary(m1)
mtest.fct(m1)
jtest.fct(m1)
wald.fct(m1, param = "all")

```

`mtest.fct(m1)` is used to test second order serial correlation.

`jtest.fct(m1)` is used to test Hansen $J$-test of overidentifying restrictions.

`wald.fct(m1, param = "all")` is used to test the null hypothesis that the population parameters of all coefficients included in the model are jointly zero.


--------------------------------------------------------------------------------

## References {.unlisted .unnumbered}


- Guillermo Corredor, Dynamic AR(1) Panel Estimation in R, <https://bookdown.org/gcorredor/dynamic_ar1_panel/dynamic_ar1_panel.html>

- Kleiber, C. and Zeileis A. (2017), Chap 3 Linear Regression, *Applied Econometrics with R*.

- Arellano M, Bond S (1998). “Dynamic panel data estimation using DPD98 for GAUSS: a guide for users.” unpublished.

- Arellano M, Bond S (2012). “Panel data estimation using DPD for Ox.” unpublished, <https://www.doornik.com/download/oxmetrics7/Ox_Packages/dpd.pdf>.

- Blundell R, Bond S (1998). “Initital Conditions and Moment Restrictions in Dynamic Panel Data Models.” *Journal of Econometrics*, **87**, 115–143.

- Roodman D (2009). “How to do xtabond2: An introduction to difference and system GMM in Stata.” *The Stata Journal*, **9**, 86-136. <https://www.stata-journal.com/article.html?article=st0159>.






