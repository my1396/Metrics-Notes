---
title: "Time Series Regression"
format: html
---


```{r}
#| label: load-packages
#| include: false
library(knitr) # load packages
library(broom)
library(kableExtra)
library(tidyverse)
library(latex2exp)
library(stargazer)
library(xts)
library(wooldridge)
```

```{r}
#| child: "_chunk-opt.qmd"
#| include: false
```

Given the dynamic relationship of time series data, there are three different ways of modeling these relationships.

1. The dependent variable $y$ is a function of current and past values of an explanatory variable $x$. That is,

    $$
    y_t = f(x_t, x_{t-1}, x_{t-2}, \ldots)
    $$

    We can think of $(y_t, x_t)$ as denoting the values of $y$ and $x$ in the current period; $x_{t-1}$ denotes the value of $x$ in the previous period, $x_{t-2}$ denotes the value of $x$ two periods ago, and so on. Because of the lagged effects, the above equation is called a **distributed lag (DL) model**.

2. Specify a model with a **lagged dependent variable** as one of the explanatory variables.

    $$
    y_t = y(y_{t-1}, x_t)
    $$

We can also combine the first two features of the above and previous equation so that we have a dynamic model with lagged values of both the *dependent* and *independent* variables, such as

$$
y_t = f(y_{t-1}, x_t, x_{t-1}, x_{t-2}, \ldots)
$$
    
Such models are called **autoregressive distributed lag models (ARDL)**. As we have shown, the ARDL model is composed of an autoregressive component, which is the dependent variable regressed on one or more of its past values, and a distributed lag component, which is the independent variable and one or more of its lagged components.

3. A third way of modeling the continuing change over several periods is via an error term. For example, using $f(\cdot)$ and $g(\cdot)$, both of which are replaced later with linear functions, we can write

    $$
    y_t = f(x_t) + e_t \quad \text{and} \quad e_t = g(e_{t-1})
    $$
    
    where the function $e_t = g(e_{t-1})$ is used to denote the dependence of the error term on its value in the previous period. In this case, $e_t$ is correlated with $e_{t-1}$, and in such a scenario, we say the errors are **serially correlated or autocorrelated**.


**Stationarity**

An assumption that we will maintain throughout this exercise is that variables in our equation are stationary, which means that a variable is one that is not explosive, nor trending, and nor wandering aimlessly without returning to its mean. A stationary variable simply means a variable whose mean, variance and other statistical properties remain constant over time.

## Finite Distributed Lags

The first dynamic relationship we consider is the first model that we introduced, which took the form of  
$y_t = f(x_t, x_{t-1}, x_{t-2}, \ldots)$,  
with the additional assumption that the relationship is **linear**, and after $q$ time periods, changes in $x$ no longer have an impact on $y$. Under these conditions, we have the multiple regression model:

$$
y_t = \alpha + \beta_0 x_t + \beta_1 x_{t-1} + \beta_2 x_{t-2} + \ldots + \beta_q x_{t-q} + e_t
$$ {#eq-FDL}

The above model can be treated in the same way as a multiple regression model. Instead of having a number of different explanatory variables, we have a number of different **lags of the same explanatory variable**. This equation can be very useful in two ways:

1. **Forecasting future values of $y$.**  

   To introduce notation for future values, suppose our sample period is $t = 1, 2, \ldots, T$.  
   We use $t$ for the index and $T$ for the sample size to emphasize the time series nature of the data.  
   Given the last observation in our sample is at $t = T$, the first post-sample observation that we wish to forecast is at $t = T + 1$.  
   The equation for this observation can be given by:

   $$
   y_{T+1} = \alpha + \beta_0 x_{T+1} + \beta_1 x_T + \beta_2 x_{T-1} + \ldots + \beta_q x_{T-q+1} + e_{T+1}
   $$

2. **Strategic Analysis.**  

   For example, to use an economic example, understanding the effects of the change in interest rate on unemployment and inflation, or the effect of advertising on sales on a firm's products.  
   The coefficient $\beta_s$ gives the change in $E(y_t)$ when $x_{t-s}$ changes by one unit, but $x$ is held constant in other periods.  
   Alternatively, if we look forward rather than backward, $\beta_s$ gives the changes in $E(y_{t+s})$ when $x_t$ changes by one unit, but $x$ in other periods is held constant. In terms of derivatives:

   $$
   \frac{\partial E(y_t)}{\partial x_{t-s}} = \frac{\partial E(y_{t+s})}{\partial x_t} = \beta_s
   $$

The effect of a one-unit change in $x_t$ is **distributed** over the current and next $q$ periods.  
It is called a **finite distributed lag model of order $q$** because it is assumed that after a finite number of periods $q$,  
changes in $x$ no longer have an impact on $y$. The coefficient $\beta_s$ is called a **distributed-lag weight** or an **$s$-period delayed multiplier**.  
The coefficient $\beta_0$ is called the **impact multiplier**.  
Adding up a portion of the coefficients gives you the **interim multipliers**.  
For example, the interim multiplier for two periods would be $(\beta_0 + \beta_1 + \beta_2)$.  
The **total multiplier** is the final effect on $y$ on the sustained increase after $q$ or more periods have elapsed and is given by the equation:

$$
\sum_{s=0}^q \beta_s
$$



## Assumptions

In distributed lag models, both $y$ and $x$ are typically random. That is, we do not know their values prior to sampling.  
We do not “set” output growth, for example, and then observe the resulting level of unemployment.  
To accommodate for this stochastic process, we assume that the $x$’s are random and that the error term $e_t$ is  
**independent of all $x$’s in the sample – past, current, and future**.  
This assumption, in conjunction with the other multiple regression assumptions, is sufficient for the least squares estimator to be unbiased and to be BLUE, conditional on the $x$’s in the sample.

The assumptions of the distributed lag model are:

1. $y_t = \alpha + \beta_0 x_t + \beta_1 x_{t-1} + \beta_2 x_{t-2} + \ldots + \beta_q x_{t-q} + e_t$
2. $y$ and $x$ are stationary random variables, and $e_t$ is independent of current, past, and future values of $x$
3. $E(e_t) = 0$
4. $\text{var}(e_t) = \sigma^2$
5. $\text{cov}(e_t, e_s) = 0 \quad t \ne s$
6. $e_t \sim N(0, \sigma^2)$



## Application: Okun's Law

We will apply the finite distributed lag model to Okun's Law. 
Arther Melvin Okun was an economist who posited that higher output growth reduces unemployment.
Mathematically, Okun's Law can be expressed as

$$
U_{t}-U_{t-1}=-\gamma(G_{t}-G_{N})
$$
where $U_{t}$ is the unemployment rate in period $t$, $G_{t}$ is the growth rate of output in period $t$, and $G_{N}$ is the "normal" growth rate, which we assume constant over time. 

We can rewrite the above equation in more familiar notation of the multiple regression model by denoting the change in unemployment as $DU_{t}=\Delta U_{t}=U_{t}-U_{t-1}.$ We then set $\gamma = \beta_{0}$ and $G_{N} = \alpha.$ Including an error term to our equation yields

$$
DU_{t}=\alpha + \beta_{0}G_{t} + \varepsilon_{t}.
$$

Acknowledging the changes in output are likely to have a distributed-lag effect on unemployment -- not all of the effect will take place instantaneously. We can then further expand our equation to

$$
DU_{t} = \alpha + \beta_{0}G_{t} + \beta_{1}G_{t-1} + \beta_{2}G_{t-2} + \ldots + \beta_{q}G_{t-q} + \varepsilon_{t}
$$

### Empirical Result

```{r}
f_name <- "data/okun.csv"
okun2 <- read_csv(f_name)
okun2 <- okun2 %>% 
    mutate(dunemp = c(NA, diff(unemp))
           )
okun2.zoo <- okun2 %>% 
    xts(x = .[,-1], order.by = as.yearqtr(.[[1]])) %>% 
    as.zoo()
okun2
```


Before we proceed, let's take a preliminary look at growth and unemployment during this time period. 

```{r fig.cap="Change in unemployment (red) and growth rate of GDP (blue)."}
ggplot(okun2 %>% gather("key", "value", gGDP, dunemp),
       aes(x = date, y = value, color = key)) +
    geom_line() + 
    labs(y="%") +
    scale_color_manual(
        values = c(gGDP = "blue", dunemp = "red"),
        labels = c(gGDP = "Growth in Real GDP", dunemp = "∆ Unemployment Rate") ) +
    theme_bw(base_size = 14) +
    theme(legend.position = c(.2, .9),
          legend.title = element_blank(),
          axis.title.x = element_blank(),
          )
```



Implement Finite Distributed Lag models (-@eq-FDL) for $q=2$ and $3$.

```{r}
library(dynlm)
okun.lag2 <- dynlm(d(unemp, 1) ~ L(gGDP, 0:2), data = okun2.zoo)
okun.lag3 <- dynlm(d(unemp, 1) ~ L(gGDP, 0:3), data = okun2.zoo)
```

Model estimates for lag length at $q=3$

```{r}
summary(okun.lag3)
```

Model estimates for lag length at $q=2$

```{r}
summary(okun.lag2)
```


A 1 percentage point increase in the growth rate of GDP leads to a fall in the change of unemployment rate by 0.44 percentage points in the current quarter, a fall of 0.09 percentage points in the next quarter. The delayed effects stop beyond the first lag.


### ARDL

A more general model is 

$$
y_{t} = \alpha + \rho\, y_{t-1} + \gamma_{0}z_{t} + \gamma_{1}z_{t-1} + v_{t},
$$
which is an **autoregressive distributed lag model** (ARDL). It is called an autoregressive distributed lag model because the dependent variable is regressed on its lagged value (the autoregressive component), and it also includes explanatory variables and their lagged values (the distributed lag component).

This equation can be estimated by linear least squares providing that the $v_t$ satisfy the usual assumptions required for least squares estimation, namely that they have zero mean and constant variance, and are not autocorrelated. 

The presence of the lagged dependent variable $y_{t−1}$ means that a large sample is required for the desirable properties of the least squares estimator to hold, but the least squares procedure is still valid providing that $v_t$ is uncorrelated with *current* and *past* values of the right-hand side variables. 

It is crucial that $v_t$ be **serial uncorrelated**. If they are serial correlated, e.g., $v_t=u_t-\rho u_t$, the least square estimator will be biased, even in large sample sizes!

Implement an ARDL model.

$$
DU_{t} = \alpha + \rho\, DU_{t-1} + \gamma_{0}G_{t} + \gamma_{1}G_{t-1} + v_{t}.
$$

```{r}
okun.ardl <- dynlm(d(unemp, 1) ~ L(d(unemp, 1), 1) + L(gGDP, 0:1), data = okun2.zoo)
summary(okun.ardl)
```


$$
\begin{aligned}
\widehat{DU}_{t} 
&= 0.429 - 0.056 \, DU_{t-1} - 0.434\,G_{t} - 0.120\,G_{t-1} \\
&\phantom{=}\;\; (.038)\quad (.059) \qquad\quad\quad (.024) \quad\quad\; (.036)\\
n &= 307, R^2=.583, \bar{R^2} = .579.
\end{aligned}
$$

A 1% increase in the change of unemployment rate from the previous quarter leads to a 0.056% decrease in the change of unemployment rate in the current quarter. This suggests a **mild mean-reverting behavior**: unemployment shocks tend to partially reverse in the following quarter, but the effect is small.

A 1% increase in the growth rate of GDP leads to a fall in the unemployment rate of 0.43% in the current quarter, a fall of 0.12% in the next quarter.

--------------------------------------------------------------------------------

## References {.unlisted .unnumbered}

- Czar Yobero, Time Series Regression with Stationary Variables: An Introduction to the ARDL Model, <https://rpubs.com/cyobero/ardl>
- Okun's Law data source: FRED database, <https://fred.stlouisfed.org/series/GDPC1>


